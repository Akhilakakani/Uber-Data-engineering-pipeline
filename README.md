# **Uber Data Engineering Project**

## **Overview**
The goal of this project is to perform data analytics on Uber data using various tools and technologies, including GCP Storage, Python, Compute Instance, Mage Data Pipeline Tool, BigQuery, and Looker Studio.

## **Project Architecture**
The pipeline follows these steps:

- **Extract**: Retrieve raw Uber trip data from an external source.
- **Transform**: Clean, preprocess, and enrich the data using Mage AI.
- **Load**: Store the transformed data into **Google BigQuery** for querying and analysis.
- **Analyze**: Generate insights and visualizations using Looker Studio.


## **Setup Instructions**
### **Prerequisites**
- Python 3.x installed
- Google Cloud account with BigQuery enabled
- Mage AI installed


## **Key Features**
✅ **Automated ETL pipeline** using Mage AI  
✅ **BigQuery integration** for scalable data analysis  
✅ **Real-time data processing** with optimized workflows  
✅ **Data visualization & insights** using Looker Studio


## **Results & Insights**
- Identified peak demand hours for Uber rides.
- Analyzed fare trends based on locations and time of day.
- Evaluated driver performance based on trip durations and ratings.


## **Challenges Faced**
- **BigQuery Optimization**: Improved query performance for large datasets.
- **Data Cleaning**: Handled missing values and inconsistencies in raw data.
- **Pipeline Automation**: Configured Mage AI workflows for seamless execution.


## **Future Enhancements**
- **Integrate real-time streaming** using Apache Kafka.
- **Deploy dashboards** using Google Data Studio.
- **Expand dataset** to include weather and traffic impact analysis.


## **Acknowledgements**
- Inspired by a Tutorial
- Special thanks to the open-source community and Mage AI contributors.
